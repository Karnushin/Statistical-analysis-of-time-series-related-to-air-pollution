{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "\n",
    "def prepare_dataframe(df, drop_cols, return_wrong_dates=False):\n",
    "    \"\"\"Preparation of dataframe for specific data\n",
    "    \n",
    "    Specificity is in that df have to contain data in separate columns ‘YY‘, ‘MM‘, ‘DD‘\n",
    "    YY must be written in 2 digits or 4, the 1st case will be transformed as 1900 + YY if YY >= 83 else 2000 + YY\n",
    "    Combinations of ‘YY‘, ‘MM‘, ‘DD‘ that don't represent real date will be dropped\n",
    "    As a result ‘YY‘, ‘MM‘, ‘DD‘ will be transformed in ‘time‘ represented time object\n",
    "    \n",
    "    Parameters:\n",
    "        df - pandas dataframe\n",
    "        drop_cols - column that should be dropped\n",
    "        return_wrong_dates - if return wrong dates if they'll be found in df\n",
    "    \n",
    "    Return:\n",
    "        Transformed dataframe only or with list of wrong dates (see “return_wrong_dates“ parameter)\n",
    "        order df (, wrong dates)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    #delete rows where date is unknown\n",
    "    df = df.dropna(subset=['YY','MM', 'DD'], how='any')\n",
    "    df = df.reset_index(drop=True)\n",
    "    #transformation of date\n",
    "    df.loc[:, 'YY':'DD'] = df.loc[:, 'YY':'DD'].astype(int)\n",
    "    for i, x in enumerate(df['YY']):\n",
    "        if x < 100:\n",
    "            df.loc[i, 'YY'] = 1900 + x if x >= 83 else 2000 + x\n",
    "\n",
    "    date_column, index_error = [], []\n",
    "    wrong_dates = []\n",
    "    for i in range(df.shape[0]):\n",
    "        try:\n",
    "            date_column.append(datetime.date(df.iloc[i,0],df.iloc[i,1],df.iloc[i,2]))\n",
    "        except ValueError:\n",
    "            warnings.warn(f\"\\nGot wrong date YY MM DD, it'll be dropped\", stacklevel=2)\n",
    "            index_error.append(i) \n",
    "    \n",
    "    wrong_dates.append(df.iloc[index_error, 0 : 3].values[0])\n",
    "    df = df.drop(index_error, axis = 0)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    df.insert(0, 'time', date_column)\n",
    "    df = df.set_index(pd.DatetimeIndex(df['time']))\n",
    "    df = df.drop(['time', 'YY', 'MM', 'DD'],axis=1)\n",
    "\n",
    "    #change obgect type to numeric if possible\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    if return_wrong_dates:\n",
    "        return df, wrong_dates\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def print_count_missing(df):\n",
    "    \"\"\"Print count of missed values in dataframe's columns between first and last valid value for the specific\n",
    "    columns\n",
    "    \n",
    "    First and last NaN are omitted\n",
    "    \n",
    "    Parameters:\n",
    "        df - pandas dataframe\n",
    "    \n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    nans_l = {}\n",
    "    fir_valid = dict().fromkeys(df.columns)\n",
    "    last_valid = dict().fromkeys(df.columns)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        ts = df[[col]].copy()\n",
    "        fir_ix = ts.first_valid_index()\n",
    "        if fir_ix is not None:\n",
    "            fir_ix = ts.index.get_loc(fir_ix)\n",
    "            last_ix = ts.index.get_loc(ts.last_valid_index())\n",
    "            ts = ts.iloc[fir_ix:last_ix+1, :]\n",
    "        #tuple for cnt nan and no-nan\n",
    "        nans_l[col] = (ts.isna().sum().values[0], ts.notnull().sum().values[0])\n",
    "        #to print first and last valid indexes\n",
    "        fir_valid[col] = ts.first_valid_index()\n",
    "        last_valid[col] = ts.last_valid_index()\n",
    "        \n",
    "    columns_names = 'Element | Count NaN | Count no-NaN | First valid date| Last valid date'\n",
    "    print(' '*(len(columns_names)//3) + 'Some information about data')\n",
    "    print('-'*len(columns_names))\n",
    "    print(columns_names)\n",
    "    print('-'*len(columns_names))\n",
    "    for col, val in nans_l.items():\n",
    "        fir_val_ix = str(fir_valid[col]).split(' ')[0]\n",
    "        last_val_ix = str(last_valid[col]).split(' ')[0]\n",
    "        cnt_nan = val[0]\n",
    "        cnt_nonan = val[1]\n",
    "        print(f'{col:<7}{cnt_nan:>8}{cnt_nonan:>15}{fir_val_ix:>18}{last_val_ix:>18}')\n",
    "        \n",
    "    print(\"\\nP.S. valid date means that before or after this date there're only missing values.\\nOf course nonvalid\\\n",
    " dates are omitted\")         \n",
    "    \n",
    "def find_borders_nan_intervals(df, col):\n",
    "    \"\"\"Finding borders of NaN intervals\n",
    "    \n",
    "    First and last NaN are omitted\n",
    "    \n",
    "    Parameters:\n",
    "        df - pandas dataframe\n",
    "        col - column's name where to search borders of nan intervals\n",
    "        \n",
    "    Return:\n",
    "        list of tuple where tuplu consist of:\n",
    "            t[0] - left border, ix of 1-st nan\n",
    "            t[1] - right border where first non-missing value was met\n",
    "            t[2] - length of the interval\n",
    "    Example:\n",
    "        [1, 1, nan, nan, 3]\n",
    "        t[0] = 2, t[1] = 4, t[2] = 2\n",
    "    \n",
    "    Note:\n",
    "        Since for dataframe with several columns for some of them there can be nan first, we would start\n",
    "        from first valid index for this specific column\n",
    "    \"\"\"\n",
    "    \n",
    "    nans_ix = []\n",
    "    fir_ix, last_ix = 0, 0\n",
    "    flag = False\n",
    "    \n",
    "    fir_val_ix = df.index.get_loc(df[col].first_valid_index())\n",
    "    last_val_ix = df.index.get_loc(df[col].last_valid_index())\n",
    "\n",
    "    for ix, val in enumerate(df[col].values):\n",
    "        #to pass first nan values\n",
    "        if ix < fir_val_ix:\n",
    "            continue\n",
    "        if ix > last_val_ix:\n",
    "            break\n",
    "        \n",
    "        if np.isnan(val) and not flag:\n",
    "            fir_ix = ix\n",
    "            flag = True\n",
    "        elif flag and not np.isnan(val):\n",
    "            flag = False\n",
    "            last_ix = ix\n",
    "            nans_ix.append((fir_ix, last_ix, last_ix - fir_ix))\n",
    "            fir_ix, last_ix = 0, 0\n",
    "            \n",
    "    return nans_ix\n",
    "\n",
    "def count_frequency(l):\n",
    "    \"\"\"Count of repeated values in list\n",
    "    \n",
    "    Parameters:\n",
    "        l - list of repeated values\n",
    "    \n",
    "    Return:\n",
    "        list of tuple where:\n",
    "            t[0] - value\n",
    "            t[1] - count of freqquency\n",
    "    \"\"\"\n",
    "    \n",
    "    d = {}\n",
    "    \n",
    "    for v in l:\n",
    "        d.setdefault(v, 0)\n",
    "        d[v] += 1\n",
    "        \n",
    "    return sorted(d.items(), key=lambda x: x[0])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
